<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebAR Video on Plane</title>
    <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.3.0/model-viewer.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            background: #f0f0f0;
        }
        model-viewer {
            width: 100%;
            height: 400px;
            max-width: 600px;
        }
        #loading {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.7);
            color: white;
            justify-content: center;
            align-items: center;
            z-index: 100;
        }
    </style>
</head>
<body>
    <h1>WebAR Video on Plane</h1>
    
    <model-viewer id="arViewer" 
        ar 
        ar-modes="webxr scene-viewer quick-look"
        camera-controls
        disable-pan
        environment-image="neutral"
        auto-rotate
        rotation-per-second="30deg">
        <button slot="ar-button">View in AR</button>
    </model-viewer>

    <video id="alphaVideo" loop playsinline crossorigin="anonymous" style="display: none;">
        <source src="Untitled Video (1).mp4" type="video/mp4">
    </video>

    <div id="loading">Loading AR experience...</div>

    <script>
        document.addEventListener("DOMContentLoaded", async () => {
            const modelViewer = document.getElementById("arViewer");
            const video = document.getElementById("alphaVideo");
            const loading = document.getElementById("loading");
            
            // Show loading indicator
            loading.style.display = 'flex';
            
            // Preload the video
            video.load();
            
            // Wait for both model viewer and video to be ready
            await Promise.all([
                new Promise(resolve => modelViewer.addEventListener('load', resolve, { once: true })),
                new Promise(resolve => video.addEventListener('canplaythrough', resolve, { once: true }))
            ]);
            
            // Set up AR session handler
            modelViewer.addEventListener('ar-status', async (event) => {
                if (event.detail.status === 'session-started') {
                    try {
                        await startARVideo(modelViewer, video);
                        loading.style.display = 'none';
                    } catch (error) {
                        console.error("AR setup failed:", error);
                        loading.textContent = "AR setup failed. Please try again.";
                    }
                } else if (event.detail.status === 'session-ended') {
                    video.pause();
                }
            });
            
            // For browsers that block autoplay, we'll start video on button click
            const arButton = modelViewer.querySelector('button[slot="ar-button"]');
            arButton.addEventListener('click', async () => {
                try {
                    await video.play();
                } catch (err) {
                    console.log("Video play requires user interaction:", err);
                    // If still blocked, we'll handle in the AR session
                }
            });
        });

        async function startARVideo(modelViewer, video) {
            // Get the Three.js scene from model-viewer
            const scene = modelViewer.scene;
            
            // Create video texture
            const videoTexture = new THREE.VideoTexture(video);
            videoTexture.encoding = THREE.sRGBEncoding;
            videoTexture.minFilter = THREE.LinearFilter;
            videoTexture.magFilter = THREE.LinearFilter;
            
            // Create plane geometry
            const geometry = new THREE.PlaneGeometry(1.5, 0.85); // Width, Height (aspect ratio ~16:9)
            const material = new THREE.MeshBasicMaterial({
                map: videoTexture,
                transparent: true,
                side: THREE.DoubleSide,
                opacity: 1
            });
            
            const plane = new THREE.Mesh(geometry, material);
            plane.position.set(0, 0, -1.5); // Position in front of camera
            plane.rotation.x = -Math.PI / 2; // Rotate to lay flat
            
            // Add plane to scene
            scene.add(plane);
            
            // Try to play video (may still be blocked by some browsers)
            try {
                await video.play();
                console.log("Video playback started successfully");
            } catch (err) {
                console.error("Video play failed:", err);
                // Some browsers require explicit user interaction
                // We'll handle this by showing a play button in AR
            }
            
            // Animation loop to update video texture
            function animate() {
                requestAnimationFrame(animate);
                if (video.readyState >= video.HAVE_ENOUGH_DATA) {
                    videoTexture.needsUpdate = true;
                }
            }
            animate();
            
            // Add click handler to play video directly in AR if blocked
            modelViewer.addEventListener('click', (event) => {
                if (video.paused) {
                    video.play().catch(e => console.log("Playback still blocked:", e));
                }
            }, { once: true });
        }
    </script>
</body>
</html>
